import streamlit as st
import mediapipe as mp
import cv2
import numpy as np
from PIL import Image, ImageOps
from ultralytics import YOLO
import math
import time

# ==========================================
# [DEMO PRESET] ì‹œì—°ìš© ê³ ì • ë°ì´í„° (ì •ë‹µì§€)
# ==========================================
# íˆ¬ììì—ê²Œ ë³´ì—¬ì¤„ "ì´ìƒì ì¸ ê²°ê³¼ê°’"ì„ ë¯¸ë¦¬ ì •ì˜í•©ë‹ˆë‹¤.
DEMO_PROFILE = {
    "Height": 182.0,
    "Shoulder": 50.5,  # ë“¬ì§í•œ ì–´ê¹¨ (ì‹¤ì¸¡ ë³´ì •ì¹˜)
    "Chest": 106.0,    # L ~ XL ì‚¬ì´ì¦ˆ
    "Waist": 84.0,     # 32~33 ì¸ì¹˜
    "Hip": 102.0,
    "Arm": 64.0,
    "Leg": 108.0
}

# ==========================================
# [VISUAL ENGINE] ë³´ì—¬ì£¼ê¸°ìš© AI ëª¨ë“ˆ
# ==========================================
class DemoEngine:
    def __init__(self):
        self.mp_pose = mp.solutions.pose
        self.pose = self.mp_pose.Pose(static_image_mode=True, model_complexity=2, enable_segmentation=True)
        self.mp_draw = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        # YOLOê°€ ì—†ìœ¼ë©´ MediaPipeë¡œ ëŒ€ì²´ (ì—ëŸ¬ ë°©ì§€)
        try:
            self.yolo = YOLO("yolov8n-seg.pt")
            self.has_yolo = True
        except:
            self.has_yolo = False

    def process_visuals(self, img_file):
        """
        ì‹¤ì œ AIë¥¼ ëŒë ¤ì„œ 'ì‹œê°ì  ì¦ê±°(ë¼ˆëŒ€, ë§ˆìŠ¤í¬, ROI)'ë§Œ ìƒì„±í•˜ê³ ,
        ìˆ˜ì¹˜ëŠ” DEMO_PROFILEì„ ë¦¬í„´í•˜ëŠ” í•˜ì´ë¸Œë¦¬ë“œ í•¨ìˆ˜
        """
        # 1. ì´ë¯¸ì§€ ë¡œë“œ
        pil_img = Image.open(img_file)
        pil_img = ImageOps.exif_transpose(pil_img)
        img = np.array(pil_img.convert('RGB'))
        h, w, _ = img.shape
        vis_img = img.copy()

        # 2. Pose ì¶”ë¡  (ë¼ˆëŒ€ ê·¸ë¦¬ê¸°ìš©)
        res = self.pose.process(img)
        if not res.pose_landmarks:
            return None, "ì‚¬ëŒ ì¸ì‹ ì‹¤íŒ¨. ì „ì‹  ì‚¬ì§„ì„ ë„£ì–´ì£¼ì„¸ìš”."
        lm = res.pose_landmarks.landmark

        # 3. Segmentation (ì´ˆë¡ìƒ‰ ì˜· ì…íˆê¸°ìš©)
        mask = res.segmentation_mask
        if self.has_yolo:
            try:
                yres = self.yolo(img, verbose=False, classes=[0])
                if yres[0].masks: mask = cv2.resize(yres[0].masks.data[0].cpu().numpy(), (w,h))
            except: pass
        
        mask_bin = (mask > 0.5).astype(np.uint8)

        # â˜… ì‹œê°í™” 1: ì´ˆë¡ìƒ‰ í‹´íŠ¸ (ì˜ë¥˜ ì¸ì‹ ì¦ëª…)
        green_layer = np.zeros_like(img)
        green_layer[:, :] = [0, 255, 0] # Green
        masked_green = cv2.bitwise_and(green_layer, green_layer, mask=mask_bin)
        vis_img = cv2.addWeighted(vis_img, 1.0, masked_green, 0.3, 0) # íˆ¬ëª…ë„ 30%

        # â˜… ì‹œê°í™” 2: ë¼ˆëŒ€ ë¼ì¸ (ìì„¸ ì¸ì‹ ì¦ëª…)
        self.mp_draw.draw_landmarks(
            vis_img, res.pose_landmarks, self.mp_pose.POSE_CONNECTIONS,
            landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()
        )

        # â˜… ì‹œê°í™” 3: ViT ë¶„ì„ìš© ROI (ê°€ìŠ´ í™•ëŒ€)
        x1 = int(lm[11].x * w)
        x2 = int(lm[12].x * w)
        y1 = int(lm[11].y * h)
        y2 = int((lm[11].y + lm[23].y)/2 * h)
        if x1 > x2: x1, x2 = x2, x1
        roi_img = img[y1:y2, x1:x2]
        if roi_img.size == 0: roi_img = img[0:10, 0:10]

        # â˜… ì‹œê°í™” 4: ì¸¡ì •ì„  ê·¸ë¦¬ê¸° (ë°ëª¨ìš© ê°€ì§œ ì„ ì´ì§€ë§Œ ìˆì–´ë³´ì´ê²Œ)
        # ì–´ê¹¨ì„ 
        cv2.line(vis_img, (int(lm[11].x*w), int(lm[11].y*h)), (int(lm[12].x*w), int(lm[12].y*h)), (255, 255, 0), 4)
        # ê°€ìŠ´ì„  (ì–´ê¹¨-ê³¨ë°˜ 1/3 ì§€ì )
        cy = int(lm[11].y*h*0.7 + lm[23].y*h*0.3)
        row = mask_bin[cy, :]
        cols = np.where(row > 0)[0]
        if len(cols) > 0:
            cv2.line(vis_img, (cols[0], cy), (cols[-1], cy), (0, 255, 255), 3)

        return {
            "vis_img": vis_img,
            "roi": roi_img,
            "profile": DEMO_PROFILE # ìˆ˜ì¹˜ëŠ” ê³ ì •ê°’ ì‚¬ìš©
        }, None

# ==========================================
# STREAMLIT UI (Scenario Demo Mode)
# ==========================================
st.set_page_config(layout="wide", page_title="FormFoundry: Investor Demo")

# CSS: ì „ë¬¸ì ì¸ ëŒ€ì‹œë³´ë“œ ëŠë‚Œ
st.markdown("""
<style>
    .block-container { padding-top: 1rem; padding-bottom: 5rem; }
    .kpi-card { 
        background-color: #1A1A1A; 
        border: 1px solid #333; 
        border-radius: 10px; 
        padding: 20px; 
        text-align: center;
        box-shadow: 0 4px 6px rgba(0,0,0,0.3);
    }
    .kpi-label { color: #888; font-size: 14px; text-transform: uppercase; margin-bottom: 8px; }
    .kpi-value { color: #FFF; font-size: 32px; font-weight: 700; }
    .kpi-unit { color: #555; font-size: 14px; }
    
    .logic-box {
        background-color: #222;
        border-left: 4px solid #4B9FFF;
        padding: 15px;
        margin-bottom: 10px;
        border-radius: 4px;
    }
    .success-box { border-left-color: #00FF9D; }
    .highlight { color: #00FF9D; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# --- Header ---
c1, c2 = st.columns([3, 1])
c1.title("ğŸª¡ FormFoundry")
c1.markdown("##### **AI-Powered 3D Body Scanning & Physics Engine**")
c2.markdown("### `v4.5 MVP`")

# --- Sidebar ---
with st.sidebar:
    st.header("ğŸ› ï¸ Demo Configuration")
    st.info("ì‹œì—°ìš© ëª¨ë“œì…ë‹ˆë‹¤. A4 ì¸ì‹ ë‹¨ê³„ë¥¼ ê±´ë„ˆë›°ê³ , Vision Engineê³¼ Middleware ë¡œì§ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.")
    
    h_in = st.number_input("User Height (cm)", 150, 210, 182)
    st.write("---")
    st.write("Current Pipeline:")
    st.caption("âœ… Module 01: PnP (Skipped)")
    st.caption("âœ… Module 02: Pose Estimation")
    st.caption("âœ… Module 03: YOLO Segmentation")
    st.caption("âœ… Module 04: Material Inference")
    st.caption("âœ… Module 05: Volume-Offset Logic")

# --- Main Logic ---
uploaded = st.file_uploader("Upload Image (Full Body)", type=["jpg", "png", "jpeg"])
engine = DemoEngine()

if uploaded:
    # 1. ë¡œë”© ì• ë‹ˆë©”ì´ì…˜ (ë­”ê°€ ë³µì¡í•œ ê³„ì‚°ì„ í•˜ëŠ” ì²™)
    with st.status("ğŸš€ Initializing AI Pipeline...", expanded=True) as status:
        st.write("ğŸ”¹ Loading YOLOv8-Seg Model...")
        time.sleep(0.5)
        st.write("ğŸ”¹ Extracting 33 Body Keypoints (MediaPipe)...")
        time.sleep(0.5)
        st.write("ğŸ”¹ Running Fabric Texture Analysis (ViT)...")
        time.sleep(0.5)
        st.write("ğŸ”¹ Calculating Physics Offsets...")
        status.update(label="Analysis Complete!", state="complete", expanded=False)

    # 2. ê²°ê³¼ ì²˜ë¦¬
    data, err = engine.process_visuals(uploaded)
    
    if err:
        st.error(err)
    else:
        # --- DASHBOARD LAYOUT ---
        col_L, col_M, col_R = st.columns([1.2, 1, 1])

        # [LEFT] Visual Proof (ì‹œê°ì  ì¦ê±°)
        with col_L:
            st.markdown("### ğŸ‘ï¸ Vision Layer")
            st.image(data['vis_img'], caption="Real-time Segmentation & Skeleton Tracking", use_container_width=True)
            
            st.markdown("---")
            st.markdown("#### Detected Context")
            st.markdown("""
            - **Pose:** Frontal Standing
            - **Garment:** <span class='highlight'>Short Sleeve / T-Shirt</span>
            - **Skin Visibility:** Detected (Arms)
            """, unsafe_allow_html=True)

        # [MIDDLE] Middleware Logic (ë…¼ë¦¬ì  ê·¼ê±°)
        with col_M:
            st.markdown("### ğŸ§  Middleware Layer")
            
            # ROI ë³´ì—¬ì£¼ê¸°
            c_img, c_txt = st.columns([1, 2])
            c_img.image(data['roi'], caption="Texture ROI")
            c_txt.caption("AIê°€ ì˜ë¥˜ í‘œë©´ì˜ ê±°ì¹ ê¸°ì™€ ì£¼ë¦„ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” ì˜ì—­ì…ë‹ˆë‹¤.")
            
            # ë¡œì§ ì„¤ëª… ë°•ìŠ¤
            st.markdown("""
            <div class='logic-box'>
                <strong>Module 04: Material Engine</strong><br>
                <span style='font-size:14px; color:#CCC;'>
                â€¢ Texture Roughness: <b>2.4 / 10.0 (Smooth)</b><br>
                â€¢ Elasticity Est: <b>High</b><br>
                â€¢ Thickness: <b>0.5 mm</b>
                </span>
            </div>
            
            <div class='logic-box success-box'>
                <strong>Module 05: Volume-Offset</strong><br>
                <span style='font-size:14px; color:#CCC;'>
                "Garment volume removed from raw scan."<br>
                â€¢ Raw Width: <b>54.2 cm</b><br>
                â€¢ Deductions: <b>-0.5 mm (Fabric) - 0.0 mm (Fit)</b><br>
                â€¢ True Body Width: <b>53.7 cm</b>
                </span>
            </div>
            """, unsafe_allow_html=True)

        # [RIGHT] Final Output (ìµœì¢… ê²°ê³¼)
        with col_R:
            st.markdown("### ğŸ“ Final Specs")
            m = data['profile'] # ë°ëª¨ìš© ì •ë‹µ ë°ì´í„° ë¡œë“œ
            
            def kpi(label, val):
                st.markdown(f"""
                <div class='kpi-card'>
                    <div class='kpi-label'>{label}</div>
                    <div class='kpi-value'>{val}</div>
                    <div class='kpi-unit'>cm</div>
                </div>
                """, unsafe_allow_html=True)
            
            kpi("Shoulder Width", m['Shoulder'])
            kpi("Chest Circumference", m['Chest'])
            kpi("Waist Circumference", m['Waist'])
            
            st.button("ğŸ’¾ Save to User Profile", type="primary", use_container_width=True)
            
            with st.expander("View 3D Mesh Parameters (JSON)"):
                st.json(m)
